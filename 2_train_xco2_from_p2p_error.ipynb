{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import Sequential\n",
    "from keras.layers import  Dense, Dropout\n",
    "from scipy.stats import gaussian_kde\n",
    "from tensorflow.python.keras import callbacks\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "scaler = StandardScaler()\n",
    "\n",
    "def read_file(file_name):\n",
    "\tfile = open(file_name)\n",
    "\tX = []\n",
    "\tk = 0\n",
    "\twhile 1:\n",
    "\t\tline = file.readline()\n",
    "\t\tk = k+1\n",
    "\t\tif k==420000:\n",
    "\t\t\tbreak\n",
    "\t\tif not line:\n",
    "\t\t\tbreak\n",
    "\t\tdata = line[:-1].split(',')\n",
    "\t\tX.append(np.array(data).astype(np.float64))\n",
    "\tX = np.array(X)\n",
    "\treturn X\n",
    "\n",
    "def process_sim_data(profile_file_path, spectral_file_path):\n",
    "    # Load data from profile.h5\n",
    "    with h5py.File(profile_file_path, 'r') as file:\n",
    "        feature = file['feature']['block0_values'][:]\n",
    "\n",
    "    # Load data from spectral.h5\n",
    "    with h5py.File(spectral_file_path, 'r') as file:\n",
    "        spectra = file['spec']['block0_values'][:]\n",
    "\n",
    "    # Process spectra data\n",
    "    for i in range(spectra.shape[0]):\n",
    "        spectra[i, 0:525] = spectra[i, 0:525] / np.mean(spectra[i, 206:216])\n",
    "        spectra[i, 525:1280] = spectra[i, 525:1280] / np.mean(spectra[i, 811:826])\n",
    "\n",
    "    input_feature = np.append(feature[:, 3:7],feature[:, 9:10],axis=1)\n",
    "    input_feature[:, 2:3] = np.cos(input_feature[:, 2:3])\n",
    "    input_feature[:, 0:1] = np.abs(input_feature[:, 1:2] - input_feature[:, 3:4])\n",
    "    input_feature = np.delete(input_feature, [1,3], axis=1)\n",
    "\n",
    "\n",
    "    # Calculate xCO2 in ppm\n",
    "    xco2 = feature[:, 10:11]\n",
    "\n",
    "    xco2_ppm = xco2 * 1e6\n",
    "    return spectra, input_feature, xco2_ppm\n",
    "\n",
    "spectra_sim, feature_sim, xco2_sim = process_sim_data('profile.h5','spectral.h5')\n",
    "\n",
    "print(spectra_sim.shape)\n",
    "\n",
    "error_sim_file = 'error_sim.h5'\n",
    "with h5py.File(error_sim_file, 'r') as file:\n",
    "    error_sim = file['bad_level'][:]\n",
    "\n",
    "for i in range(5):\n",
    "    error_sim = np.append(error_sim,error_sim[:10000,:],axis=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.zeros([60000,1])\n",
    "years[:10000] = 2016\n",
    "years[10000:20000] = 2017\n",
    "years[20000:30000] = 2018\n",
    "years[30000:40000] = 2019\n",
    "years[40000:50000] = 2020\n",
    "years[50000:60000] = 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_exp_file(file_path,p_file):\n",
    "\n",
    "    \n",
    "    with h5py.File(file_path, 'r') as h5file:\n",
    "        x = h5file['x'][:]\n",
    "        error = h5file['bad_level'][:]\n",
    "        # y = h5file['y'][:]\n",
    "    print(x.shape)\n",
    "    sample_size = x.shape[0]\n",
    "\n",
    "    y = np.asarray(read_file(p_file))\n",
    "\n",
    "    feature = np.append(y[:,4:8],y[:,14:15],axis=1)\n",
    "    feature[:,2:3] = np.cos(feature[:,2:3])\n",
    "    feature[:,0:1] = np.abs(feature[:,1:2] - feature[:,3:4])\n",
    "    feature = np.delete(feature, [1,3], axis=1)\n",
    "\n",
    "    input_nn = np.append(x, feature, axis=1)\n",
    "    ouput_nn = y[:, 11:12]\n",
    "    error_nn = error[:,:]\n",
    "    \n",
    "    # # add year\n",
    "    year = int(file_path.split('_')[-1].split('.')[0]) + 2000\n",
    "    input_nn = np.append(input_nn, np.full((sample_size, 1), year), axis=1)\n",
    "    \n",
    "    return sample_size, input_nn, ouput_nn, error_nn\n",
    "\n",
    "\n",
    "file_paths = [\n",
    "    'exp_16.h5',\n",
    "    'exp_17.h5',\n",
    "    'exp_18.h5',\n",
    "    'exp_19.h5',\n",
    "    'exp_20.h5',\n",
    "    'expplume_17.h5',\n",
    "    'expplume_20.h5'\n",
    "]\n",
    "\n",
    "p_paths = [\n",
    "    'train_16.dat',\n",
    "    'train_17.dat',\n",
    "    'train_18.dat',\n",
    "    'train_19.dat',\n",
    "    'train_20.dat',\n",
    "    'trainplume_17.dat',\n",
    "    'trainplume_20.dat'\n",
    "]\n",
    "\n",
    "input_nn_test = []\n",
    "xco2_test = []\n",
    "num_list = []\n",
    "error_test = []\n",
    "for file_path,p_path in zip(file_paths,p_paths):\n",
    "    sample_data_num, sampled_data_in, sampled_data_xco2, sampled_error = process_exp_file(file_path,p_path)\n",
    "    input_nn_test.append(sampled_data_in)\n",
    "    xco2_test.append(sampled_data_xco2)\n",
    "    num_list.append(sample_data_num)\n",
    "    error_test.append(sampled_error)\n",
    "\n",
    "input_nn_test = np.vstack(input_nn_test)\n",
    "error_test = np.vstack(error_test)\n",
    "xco2_test = np.vstack(xco2_test)\n",
    "num_pro = np.array(num_list)\n",
    "\n",
    "print(\"Input features shape:\", input_nn_test.shape)\n",
    "print(\"xco2 shape:\", xco2_test.shape)\n",
    "print(\"shape:\", num_pro.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_16_18 = np.append(error_test[:38626,:],error_test[100421:102421,:],axis=0)\n",
    "error_16_18.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_max = (error_16_18 >0).any(axis=0).astype(float)\n",
    "\n",
    "indices_to_drop = np.where(union_max > 0.5)[0]\n",
    "\n",
    "input_nn_test = np.delete(input_nn_test, indices_to_drop, axis=1)\n",
    "spectra_sim = np.delete(spectra_sim, indices_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_label = '2band_2angle_year_retp_error_xco2'\n",
    "\n",
    "input_nn = np.append(spectra_sim,feature_sim,axis=1)#spectra\n",
    "input_nn = np.append(input_nn,years,axis=1)\n",
    "\n",
    "\n",
    "scaler.fit(input_nn)  \n",
    "[ux1,sx1]=[scaler.mean_,scaler.var_]\n",
    "input_nn_test = scaler.transform(input_nn_test)\n",
    "input_nn = scaler.transform(input_nn)\n",
    "\n",
    "\n",
    "scaler.fit(xco2_sim)  \n",
    "[uy1,sy1]=[scaler.mean_,scaler.var_]\n",
    "output_nn_test = scaler.transform(xco2_test)\n",
    "output_nn = scaler.transform(xco2_sim)\n",
    "\n",
    "\n",
    "\n",
    "input_nn = np.append(input_nn,input_nn_test[0:38626,:],axis=0)#combined 2016 samples\n",
    "output_nn = np.append(output_nn,output_nn_test[0:38626,:],axis=0)\n",
    "\n",
    "np.savetxt(\"ux_\"+model_label+\".dat\",ux1, fmt=\"%15.5e\",delimiter=',')\n",
    "np.savetxt(\"sx_\"+model_label+\".dat\",sx1, fmt=\"%15.5e\",delimiter=',')\n",
    "np.savetxt(\"uy_\"+model_label+\".dat\",uy1, fmt=\"%15.5e\",delimiter=',')\n",
    "np.savetxt(\"sy_\"+model_label+\".dat\",sy1, fmt=\"%15.5e\",delimiter=',')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(input_nn,output_nn,test_size=0.1, random_state=0)\n",
    "print(input_nn.shape,output_nn.shape)\n",
    "\n",
    "from tensorflow.keras.losses import Huber\n",
    "huber_loss = Huber(delta=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer=[1000,500,300,100,20]\n",
    "n_features = input_nn.shape[1]\n",
    "filepath=\"nn/train_\"+model_label+\".h5\"\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(layer[0], activation='relu', kernel_initializer='he_uniform', input_shape=(n_features,)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(layer[1], activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(layer[2], activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(layer[3], activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(layer[4], activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(output_nn.shape[1]))\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss=huber_loss,metrics=['mae'])\n",
    "model.summary()\n",
    "checkpoint=callbacks.ModelCheckpoint(filepath,monitor='val_loss',verbose=0,save_best_only=True,mode='min')\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',   \n",
    "    patience=15,          \n",
    "    mode='min',           \n",
    "    verbose=1             \n",
    ")\n",
    "callbacks_list=[checkpoint,early_stopping]\n",
    "\n",
    "\n",
    "model.fit(train_X, train_y, epochs=1000, batch_size=128,callbacks=callbacks_list, validation_split = 0.1  ,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (38626, 1280)\n",
    "# (39850, 1280) 78476\n",
    "# (35945, 1280) 114421\n",
    "# (36452, 1280) 150873\n",
    "# (43277, 1280) 194150\n",
    "res = model.predict(test_X)\n",
    "MLP = scaler.inverse_transform(res)\n",
    "LBL = scaler.inverse_transform(test_y)\n",
    "\n",
    "\n",
    "def r2(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculation of the unadjusted r-squared, goodness of fit metric\n",
    "    \"\"\"\n",
    "    sse  = np.square( y_pred - y_true ).sum()\n",
    "    sst  = np.square( y_true - y_true.mean() ).sum()\n",
    "    return 1 - sse/sst\n",
    "\n",
    "xy = (np.append(MLP, LBL,axis=1)).T\n",
    "z = gaussian_kde(xy)(xy)\n",
    "z=(z-np.min(z))/(np.max(z)-np.min(z))\n",
    "idx = z.argsort()\n",
    "MMLP, LLBL, z = MLP[idx], LBL[idx], z[idx]\n",
    "slope, intercept = np.polyfit(LLBL[:,0], MMLP[:,0], 1)\n",
    "xyline = np.linspace(0.95*np.min(LBL),1.05*np.max(LBL),61)\n",
    "\n",
    "fig = plt.figure(figsize=(8,7))\n",
    "figg,ax = plt.subplots()\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "plt.ylabel('Predicted [ppm]',fontname=\"serif\",fontsize=14)\n",
    "plt.xlabel('Ideal/OCO-2 [ppm]',fontname=\"serif\",fontsize=14)\n",
    "plt.axis([390,425,390,425])\n",
    "text1 = 'N:'+str(len(LBL)) \n",
    "text2 = 'R$^2$:'+str(\"%.3f\" % r2(LBL,MLP))\n",
    "text3 = 'ME: '+str(\"%.3f\" % np.mean(LBL-MLP))+' ppm'\n",
    "text4 = 'RMSE: '+str(\"%.3f\" % np.sqrt(mean_squared_error(LBL, MLP)))+' ppm'\n",
    "plt.plot(xyline, xyline, 'r-',label='Ideal$\\pm$1%', linewidth=2)\n",
    "plt.fill_between(xyline, xyline*1.01, xyline*0.99,\n",
    "    alpha=0.5, edgecolor='0.4', facecolor='0.4',\n",
    "    linewidth=1, linestyle='--', antialiased=True)\n",
    "plt.scatter(LLBL, MMLP, c=z,s=7, alpha=1.0)#facecolors='none',\n",
    "plt.colorbar(label='Number density')\n",
    "plt.tick_params(labelsize=14)\n",
    "plt.legend(fontsize=14)\n",
    "plt.ticklabel_format(style='plain', scilimits=(0, 0), axis='both')\n",
    "plt.text(0.02,0.85,text1,ha='left',va='top',transform=ax.transAxes,fontname=\"serif\",fontsize=14)\n",
    "plt.text(0.02,0.80,text2,ha='left',va='top',transform=ax.transAxes,fontname=\"serif\",fontsize=14)\n",
    "plt.text(0.02,0.75,text3,ha='left',va='top',transform=ax.transAxes,fontname=\"serif\",fontsize=14)\n",
    "plt.text(0.02,0.70,text4,ha='left',va='top',transform=ax.transAxes,fontname=\"serif\",fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(model_label+\"_testdata.png\",dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('TensorFlow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ab04d12582a83e4435fb339fd2470ec9ec0baee6e6e32c8da173585569199a02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
